# üì¶ M√≥dulo de Base de Datos (Equipo 3 ‚Äì Almacenamiento)

Este m√≥dulo contiene todo lo necesario para levantar las bases de datos del proyecto Big Data del Equipo 3:

- **PostgreSQL 15**
- **pgAdmin 4**
- **MongoDB 6**
- **Mongo Express**

Todo est√° contenido en un √∫nico archivo `docker-compose.yml` para evitar problemas de compatibilidad entre ramas.

Adem√°s, el archivo `info.txt` incluye el script del **consumidor Spark EVOLUCIONADO para insertar a las bdd** que debe copiarse dentro del contenedor Spark del m√≥dulo de procesamiento.

## üö® ADVERTENCIA IMPORTANTE (EN CASO DE SALIR ERROR AL EJECUTAR EL SPARK NUEVO)

Este m√≥dulo utiliza Spark + Kafka + PostgreSQL + MongoDB en contenedores Docker.
Para que todo funcione correctamente, DEBES cumplir dos requisitos cr√≠ticos antes de ejecutar el proyecto.

‚ö† 1) Verificar que los puertos NO est√©n ocupados

Si alguno de los siguientes puertos est√° siendo usado por otro servicio, Docker NO levantar√° los contenedores.

Puertos utilizados por este proyecto
Servicio	Puerto Local ‚Üí Contenedor
PostgreSQL	5433 ‚Üí 5432
pgAdmin	5050 ‚Üí 80
MongoDB	27017 ‚Üí 27017
Mongo Express	8087 ‚Üí 8081

# ‚ö† 2) Spark, PostgreSQL y MongoDB deben estar en la MISMA red Docker!!!
üìå Problema que descubrimos:

Si Spark est√° en la red bigdata_net
y las bases de datos est√°n en la red basededatos_equipo3_iot_network
entonces Spark NO puede resolver los hostnames como:

postgres_iot

mongo_iot

Y provoca errores como:

psycopg2.OperationalError: could not translate host name "postgres_iot": Temporary failure in name resolution

üìå Soluci√≥n correcta (ya aplicada en el docker-compose final):

Todos los contenedores deben estar en una sola red compartida, por ejemplo:

networks:
  bigdata_net:
    driver: bridge

Y cada servicio debe declarar:

networks:
  - bigdata_net

‚úî ¬øC√≥mo verificar que est√°n en la misma red?

Ejecutar:

docker network inspect bigdata_net


Ah√≠ deber√°n aparecer todos los CONTENEDORES:

spark-master

spark-worker

spark-submit

postgres_iot

mongo_iot

kafka

zookeeper

Si alguno NO est√°, Spark no podr√° insertar en las BDD.

# üîß 3) Unificar Spark y las Bases de Datos en una sola red Docker

Para que Spark pueda insertar en PostgreSQL y MongoDB, TODOS deben estar en la misma red Docker.
Si no, Spark NO puede resolver los hostnames:

postgres_iot

mongo_iot

Y marca errores como:

psycopg2.OperationalError: could not translate host name "postgres_iot"

‚úî C√≥mo solucionarlo 

Tienes dos opciones, dependiendo de qu√© contenedor est√© fuera de la red.

üÖ∞Ô∏è OPCI√ìN A ‚Äî Mover Spark a la red de las bases de datos

Si Spark est√° en una red diferente (por ejemplo bigdata_net),
usa este comando:

docker network connect basededatos_equipo3_iot_network spark-submit
docker network connect basededatos_equipo3_iot_network spark-master
docker network connect basededatos_equipo3_iot_network spark-worker


Listo: Spark ahora ve a Mongo y PostgreSQL.

üÖ±Ô∏è OPCI√ìN B ‚Äî Mover las BDD a la red de Spark

Si Spark usa la red bigdata_net, entonces conecta:

docker network connect bigdata_net postgres_iot
docker network connect bigdata_net mongo_iot
docker network connect bigdata_net mongo_express_iot
docker network connect bigdata_net pgadmin_iot

üìù C√≥mo verificar que todo est√° OK

Ejecuta:

docker inspect spark-submit


Debes ver algo como:

"Networks": {
    "bigdata_net": {},
    "basededatos_equipo3_iot_network": {}
}

Si aparecen dos redes, est√° perfecto.

üéØ Recomendaci√≥n del equipo

Usa una sola red unificada para evitar confusiones:

networks:
  bigdata_net:
    driver: bridge


Y en cada servicio:

networks:
  - bigdata_net


As√≠ todos los contenedores:

Kafka

Spark

PostgreSQL

MongoDB

pgAdmin

Mongo Express

Est√°n garantizados de poder comunicarse.

## üìÅ **Contenido de esta carpeta**

| Archivo                | Descripci√≥n |
|-----------------------|-------------|
| `docker-compose.yml`  | Orquestaci√≥n de PostgreSQL, pgAdmin, MongoDB y Mongo Express |
| `schema_postgres.sql` | Script SQL que crea todas las tablas relacionales |
| `mongo-init.js`       | Script de inicializaci√≥n de MongoDB (colecciones e √≠ndices) |
| `test_postgres.py`    | Prueba r√°pida de conexi√≥n a PostgreSQL |
| `info.txt`            | Contiene el script actualizado del consumidor Spark (para copiar a su m√≥dulo) |
| `README.md`           | Este documento |

---

# 1Ô∏è‚É£ Requisitos previos IMPORTANTE

Antes de usar este m√≥dulo, debes tener instalado:

antes de compilar el spark se debe:
- PONER psycopg2-binary pymongo en el archivo Dockerfile.spark para que funcionen las librerias
![imagen ejemplo]({053E51B7-E1E2-4992-99A4-58AE5716C3A1}.png)
esto instala las librerias para mongo y postgre, pero si ya lo iniciaste puedes hacerlo de nuevo, generar la build y solo se instalara eso sin que se instale todo de nuevo
- **Docker Desktop**
- **Python 3.10+**
- Librer√≠a necesaria para pruebas:

comando:
python -m pip install psycopg2-binary


# 2Ô∏è‚É£ Levantar la infraestructura de bases de datos

Navegar dentro de esta carpeta:

Emergentes_BigData/BaseDeDatos_Equipo3/


Y ejecutar:

docker compose up -d


Esto levantar√°:

üêò postgres_iot

Base de datos PostgreSQL

Puerto expuesto: 5433:5432

Autocarga del script schema_postgres.sql

üñ• pgadmin_iot

Panel gr√°fico para PostgreSQL

Puerto: 5050:80

Acceso v√≠a navegador

üçÉ mongo_iot

Base de datos MongoDB

Puerto expuesto: 27017:27017

Ejecuta autom√°ticamente mongo-init.js

üåê mongo_express_iot

Panel web para MongoDB

Puerto: 8087:8081

Autenticaci√≥n activada

Los contenedores se inician en la red interna del proyecto:

basededatos_equipo3_iot_network

# 3Ô∏è‚É£ Acceder a pgAdmin

Abrir en el navegador:

http://localhost:5050


Credenciales:

Email: admin@iot.com

Password: admin123

Registrar un nuevo servidor:

Campo	Valor
Name	PostgreSQL IoT
Host	postgres_iot
User	postgres
Password	12345
Database	SensoresIoT
# 4Ô∏è‚É£ Acceder a Mongo Express

Abrir:

http://localhost:8087


Credenciales:

User: admin

Password: admin123

La base se llama:

sensores_iot


Colecciones creadas autom√°ticamente:

sensor

sensor_aire

sensor_sonido

sensor_soterrado

# 5Ô∏è‚É£ ¬øQu√© tablas/colecciones se crean autom√°ticamente?
üêò PostgreSQL (schema_postgres.sql)

sensor

sensor_aire

sensor_sonido

sensor_soterrado

Los √≠ndices tambi√©n se configuran autom√°ticamente.

üçÉ MongoDB (mongo-init.js)

sensor

sensor_aire

sensor_sonido

sensor_soterrado

Todos con sus √≠ndices espec√≠ficos.

# 6Ô∏è‚É£ C√≥mo ingresar manualmente a PostgreSQL
En la ruta de base de datos 3:

docker exec -it postgres_iot psql -U postgres -d "SensoresIoT"

Listar tablas:
\dt

Ver contenidos:
SELECT * FROM sensor;
SELECT * FROM sensor_aire;
SELECT * FROM sensor_sonido;
SELECT * FROM sensor_soterrado;

# 7Ô∏è‚É£ C√≥mo ingresar a Mongo desde consola

En la ruta de base de datos 3:

docker exec -it mongo_iot mongosh


Luego:

use sensores_iot
db.sensor.find().pretty()
db.sensor_aire.find().pretty()
db.sensor_sonido.find().pretty()
db.sensor_soterrado.find().pretty()


# 8Ô∏è‚É£ Relaci√≥n con el m√≥dulo Spark (IMPORTANTE)

El archivo:

info.txt

contiene el script completo del consumidor Spark, encargado de leer Kafka y escribir en:

PostgreSQL (backup)

MongoDB (base principal)

Ese archivo debe ser copiado en su totalidad dentro del m√≥dulo de Spark (contenedor spark-submit) en la carpeta correspondiente.

‚ö† Spark NO est√° dentro de este m√≥dulo.
‚ö† Este README solo documenta la capa de almacenamiento.

